{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "import gdown\n",
    "\n",
    "# Step 1: Clone the GitHub Repository\n",
    "if not os.path.exists(\"MHyEEG\"):\n",
    "    !git clone https://github.com/alessioborgi/MHyEEG.git\n",
    "\n",
    "# Navigate to the repository\n",
    "ios.chdir(\"MHyEEG\")\n",
    "\n",
    "# Step 2: Download and Extract DEAP Dataset\n",
    "def download_and_extract_deap(dataset_url, output_dir=\"data\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    zip_path = os.path.join(output_dir, \"DEAP.zip\")\n",
    "    gdown.download(dataset_url, zip_path, quiet=False)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(output_dir)\n",
    "    print(f\"Dataset extracted to {output_dir}\")\n",
    "\n",
    "# Provide the dataset URL\n",
    "DEAP_URL = \"https://drive.google.com/uc?id=YOUR_FILE_ID\"  # Replace YOUR_FILE_ID with actual ID\n",
    "data_dir = \"data\"\n",
    "download_and_extract_deap(DEAP_URL, data_dir)\n",
    "\n",
    "# Step 3: Preprocess the Dataset\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return lfilter(b, a, data, axis=0)\n",
    "\n",
    "def preprocess_deap(input_dir, output_file):\n",
    "    eeg_data = []\n",
    "    labels = []\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.mat'):\n",
    "            data = loadmat(os.path.join(input_dir, file_name))\n",
    "            eeg = data['data'][:, :32]  # First 32 channels are EEG\n",
    "            label = data['labels'][:, :2]  # First two labels are valence and arousal\n",
    "            fs = 128  # Sampling frequency for DEAP\n",
    "            eeg = bandpass_filter(eeg, 1, 45, fs)\n",
    "            eeg_data.append(eeg)\n",
    "            labels.append(label)\n",
    "    np.savez(output_file, eeg=np.array(eeg_data), labels=np.array(labels))\n",
    "\n",
    "input_dir = os.path.join(data_dir, \"DEAP\")\n",
    "output_file = os.path.join(data_dir, \"preprocessed_deap_data.npz\")\n",
    "preprocess_deap(input_dir, output_file)\n",
    "\n",
    "# Step 4: Create PyTorch Dataset Loader\n",
    "class DEAPDataset(Dataset):\n",
    "    def __init__(self, data_file):\n",
    "        data = np.load(data_file)\n",
    "        self.eeg = data['eeg']\n",
    "        self.labels = data['labels']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg = self.eeg[idx]\n",
    "        label = self.labels[idx][:2]  # Valence and Arousal\n",
    "        return torch.tensor(eeg, dtype=torch.float32), torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "# Step 5: Reuse Hypercomplex Model\n",
    "from models.hyperfusenet import HyperFuseNet  # Assuming HyperFuseNet is in models\n",
    "\n",
    "# Step 6: Define Training Script\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for eeg, labels in dataloader:\n",
    "        eeg, labels = eeg.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(eeg)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Training Configuration\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    dataset = DEAPDataset(output_file)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model = HyperFuseNet(input_dims={'eeg': 32}, hidden_dim=128, output_dim=2, n=4).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(20):\n",
    "        loss = train(model, dataloader, optimizer, criterion, device)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {loss:.4f}\")\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
